{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from spinn.data.nli.load_nli_data import convert_binary_bracketing\n",
    "from spinn.util.catalan import ShiftProbabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "\n",
    "sample = [\n",
    "    {\"annotator_labels\": [\"neutral\"], \"genre\": \"government\", \"gold_label\": \"neutral\", \"pairID\": \"335730n\", \"promptID\": \"335730n\", \"sentence1\": \"Conceptually cream skimming has two basic dimensions - product and geography.\", \"sentence1_binary_parse\": \"( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )\", \"sentence1_parse\": \"(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))\", \"sentence2\": \"Product and geography are what make cream skimming work. \", \"sentence2_binary_parse\": \"( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )\", \"sentence2_parse\": \"(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))\"},\n",
    "    {\"annotator_labels\": [\"entailment\"], \"genre\": \"telephone\", \"gold_label\": \"entailment\", \"pairID\": \"249628e\", \"promptID\": \"249628e\", \"sentence1\": \"you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him\", \"sentence1_binary_parse\": \"( you ( ( know ( during ( ( ( the season ) and ) ( i guess ) ) ) ) ( at ( at ( ( your level ) ( uh ( you ( ( ( lose them ) ( to ( the ( next level ) ) ) ) ( if ( ( if ( they ( decide ( to ( recall ( the ( the ( parent team ) ) ) ) ) ) ) ) ( ( the Braves ) ( decide ( to ( call ( to ( ( recall ( a guy ) ) ( from ( ( triple A ) ( ( ( then ( ( a ( double ( A guy ) ) ) ( ( goes up ) ( to ( replace him ) ) ) ) ) and ) ( ( a ( single ( A guy ) ) ) ( ( goes up ) ( to ( replace him ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) )\", \"sentence1_parse\": \"(ROOT (S (NP (PRP you)) (VP (VBP know) (PP (IN during) (NP (NP (DT the) (NN season)) (CC and) (NP (FW i) (FW guess)))) (PP (IN at) (IN at) (NP (NP (PRP$ your) (NN level)) (SBAR (S (INTJ (UH uh)) (NP (PRP you)) (VP (VBP lose) (NP (PRP them)) (PP (TO to) (NP (DT the) (JJ next) (NN level))) (SBAR (IN if) (S (SBAR (IN if) (S (NP (PRP they)) (VP (VBP decide) (S (VP (TO to) (VP (VB recall) (NP (DT the) (DT the) (NN parent) (NN team)))))))) (NP (DT the) (NNPS Braves)) (VP (VBP decide) (S (VP (TO to) (VP (VB call) (S (VP (TO to) (VP (VB recall) (NP (DT a) (NN guy)) (PP (IN from) (NP (NP (RB triple) (DT A)) (SBAR (S (S (ADVP (RB then)) (NP (DT a) (JJ double) (NNP A) (NN guy)) (VP (VBZ goes) (PRT (RP up)) (S (VP (TO to) (VP (VB replace) (NP (PRP him))))))) (CC and) (S (NP (DT a) (JJ single) (NNP A) (NN guy)) (VP (VBZ goes) (PRT (RP up)) (S (VP (TO to) (VP (VB replace) (NP (PRP him))))))))))))))))))))))))))))\", \"sentence2\": \"You lose the things to the following level if the people recall.\", \"sentence2_binary_parse\": \"( You ( ( ( ( lose ( the things ) ) ( to ( the ( following level ) ) ) ) ( if ( ( the people ) recall ) ) ) . ) )\", \"sentence2_parse\": \"(ROOT (S (NP (PRP You)) (VP (VBP lose) (NP (DT the) (NNS things)) (PP (TO to) (NP (DT the) (JJ following) (NN level))) (SBAR (IN if) (S (NP (DT the) (NNS people)) (VP (VBP recall))))) (. .)))\"},\n",
    "    {\"annotator_labels\": [\"entailment\"], \"genre\": \"fiction\", \"gold_label\": \"entailment\", \"pairID\": \"169837e\", \"promptID\": \"169837e\", \"sentence1\": \"One of our number will carry out your instructions minutely.\", \"sentence1_binary_parse\": \"( ( One ( of ( our number ) ) ) ( ( will ( ( ( carry out ) ( your instructions ) ) minutely ) ) . ) )\", \"sentence1_parse\": \"(ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (PRP$ our) (NN number)))) (VP (MD will) (VP (VB carry) (PRT (RP out)) (NP (PRP$ your) (NNS instructions)) (ADVP (RB minutely)))) (. .)))\", \"sentence2\": \"A member of my team will execute your orders with immense precision.\", \"sentence2_binary_parse\": \"( ( ( A member ) ( of ( my team ) ) ) ( ( will ( ( execute ( your orders ) ) ( with ( immense precision ) ) ) ) . ) )\", \"sentence2_parse\": \"(ROOT (S (NP (NP (DT A) (NN member)) (PP (IN of) (NP (PRP$ my) (NN team)))) (VP (MD will) (VP (VB execute) (NP (PRP$ your) (NNS orders)) (PP (IN with) (NP (JJ immense) (NN precision))))) (. .)))\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "shift_probabilites = ShiftProbabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Methods\n",
    "\n",
    "def product(p):\n",
    "    return reduce(lambda x, y: x*y, p, 1.0)\n",
    "\n",
    "def binary_parse(sentence, transitions):\n",
    "    \"\"\"\n",
    "    Generate a binary parse string using shift-reduce transitions.\n",
    "    \"\"\"\n",
    "    buf = list(reversed(sentence))\n",
    "    stack = []\n",
    "    \n",
    "    for t in transitions:\n",
    "        if t == 0:\n",
    "            stack.append(buf.pop())\n",
    "        elif t == 1:\n",
    "            right = stack.pop()\n",
    "            left = stack.pop()\n",
    "            stack.append('( ' + left + ' ' + right + ' )')\n",
    "\n",
    "    return stack[0]\n",
    "\n",
    "def uniform_random_transitions(N):\n",
    "    \"\"\"\n",
    "    Given a desired sentence length, generate a sequence of shift-reduce\n",
    "    transitions by uniformly sampling a transition at each timestep.\n",
    "    \"\"\"\n",
    "    seq_length = N*2-1\n",
    "    buf = range(N)\n",
    "    stack = []\n",
    "    ts = []\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        t = np.random.choice([0, 1])\n",
    "        if len(stack) < 2: # Can't reduce\n",
    "            t = 0\n",
    "        if len(buf) < 1: # Can't shift\n",
    "            t = 1\n",
    "        if t == 0:\n",
    "            stack.append(buf.pop())\n",
    "        if t == 1:\n",
    "            stack.append(stack.pop() + stack.pop())\n",
    "        ts.append(t)\n",
    "\n",
    "    return ts\n",
    "\n",
    "def uniform_random_trees(N):\n",
    "    \"\"\"\n",
    "    Given a desired sentence length, generate a sequence of shift-reduce\n",
    "    transitions such that the sequence is uniformly random. At each\n",
    "    timestep sample from the catalan pyramid distribution.\n",
    "    \"\"\"\n",
    "    seq_length = N*2-1\n",
    "    buf = range(N)\n",
    "    stack = []\n",
    "    ts = []\n",
    "    \n",
    "    N_reduces = 0\n",
    "    \n",
    "    for i in range(seq_length):\n",
    "        shift_probability = shift_probabilites.prob(N_reduces, i, N)\n",
    "        p = [shift_probability, 1. - shift_probability]\n",
    "        t = np.random.choice([0, 1], p=p)\n",
    "        if len(stack) < 2: # Can't reduce\n",
    "            t = 0\n",
    "        if len(buf) < 1: # Can't shift\n",
    "            t = 1\n",
    "        if t == 0:\n",
    "            stack.append(buf.pop())\n",
    "        if t == 1:\n",
    "            N_reduces += 1\n",
    "            stack.append(stack.pop() + stack.pop())\n",
    "        ts.append(t)\n",
    "\n",
    "    return ts\n",
    "\n",
    "def brute_force_transitions_helper(N_stack, N_buf, N_remaining):\n",
    "    \"\"\"\n",
    "    Return all possible suffixes.\n",
    "    \"\"\"\n",
    "    suffixes = []\n",
    "    probabilities = []\n",
    "    if N_remaining == 1:\n",
    "        suffixes.append([1])\n",
    "        probabilities.append([1.0])\n",
    "    else:\n",
    "        cant_shift = N_buf == 0\n",
    "        cant_reduce = N_stack < 2\n",
    "        shift_probability = 1.0 if cant_reduce else 0.5\n",
    "        reduce_probability = 1.0 if cant_shift else 0.5\n",
    "        if not cant_shift:\n",
    "            s, p = brute_force_transitions_helper(N_stack + 1, N_buf - 1, N_remaining - 1)\n",
    "            for suffix, probability in zip(s, p):\n",
    "                suffixes.append([0] + suffix)\n",
    "                probabilities.append([shift_probability] + probability)\n",
    "        if not cant_reduce:\n",
    "            s, p = brute_force_transitions_helper(N_stack - 1, N_buf, N_remaining - 1)\n",
    "            for suffix, probability in zip(s, p):\n",
    "                suffixes.append([1] + suffix)\n",
    "                probabilities.append([reduce_probability] + probability)\n",
    "    return suffixes, probabilities\n",
    "\n",
    "def brute_force_transitions(N):\n",
    "    \"\"\"\n",
    "    Given a desired length, generate all possible sequences of shift-reduce\n",
    "    transitions. Also return the expectation of each sequence.\n",
    "    \"\"\"\n",
    "    seq_length = N*2-1\n",
    "    \n",
    "    sequences, probabilities = brute_force_transitions_helper(N_stack=0, N_buf=N, N_remaining=seq_length)\n",
    "    \n",
    "    return sequences, probabilities\n",
    "\n",
    "def catalan_transitions_helper(N_reduces, timestep, N):\n",
    "    \"\"\"\n",
    "    Return all possible suffixes.\n",
    "    \"\"\"\n",
    "    suffixes = []\n",
    "    probabilities = []\n",
    "    if timestep == 2 * N - 2:\n",
    "        suffixes.append([1])\n",
    "        probabilities.append([1.0])\n",
    "    else:\n",
    "        shift_probability = shift_probabilites.prob(N_reduces, timestep, N)\n",
    "        reduce_probability = 1.0 - shift_probability\n",
    "        if shift_probability > 0:\n",
    "            s, p = catalan_transitions_helper(N_reduces, timestep + 1, N)\n",
    "            for suffix, probability in zip(s, p):\n",
    "                suffixes.append([0] + suffix)\n",
    "                probabilities.append([shift_probability] + probability)\n",
    "        if reduce_probability > 0:\n",
    "            s, p = catalan_transitions_helper(N_reduces + 1, timestep + 1, N)\n",
    "            for suffix, probability in zip(s, p):\n",
    "                suffixes.append([1] + suffix)\n",
    "                probabilities.append([reduce_probability] + probability)\n",
    "    return suffixes, probabilities\n",
    "\n",
    "def catalan_transitions(N):\n",
    "    \"\"\"\n",
    "    Given a desired length, generate all possible sequences of shift-reduce\n",
    "    transitions. Also return the expectation of each sequence.\n",
    "    \"\"\"\n",
    "    seq_length = N*2-1\n",
    "    \n",
    "    sequences, probabilities = catalan_transitions_helper(N_reduces=0, timestep=0, N=N)\n",
    "    \n",
    "    return sequences, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: Successfully generate a binary parse string.\n",
    "\n",
    "parse = sample[0]['sentence1_binary_parse']\n",
    "sentence, transitions = convert_binary_bracketing(parse)\n",
    "\n",
    "actual = parse\n",
    "expected = binary_parse(sentence, transitions)\n",
    "\n",
    "assert actual == expected, 'Did not parse correctly.'\n",
    "\n",
    "# repeat for posterity\n",
    "expected = binary_parse(sentence, transitions)\n",
    "\n",
    "assert actual == expected, 'Running binary_parse twice is problematic.'\n",
    "\n",
    "# negative test\n",
    "expected = binary_parse(sentence, transitions)\n",
    "\n",
    "assert 'actual' != expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1], 19)\n",
      "([0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1], 19)\n",
      "([0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], 19)\n",
      "([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1], 19)\n",
      "([0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], 19)\n",
      "([0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1], 19)\n",
      "([0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1], 19)\n",
      "([0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1], 19)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Generate a handful of random trees for a fixed length.\n",
    "\n",
    "rounds = 10\n",
    "N = 10 # sentence length\n",
    "\n",
    "for _ in range(rounds):\n",
    "    tree = uniform_random_transitions(N)\n",
    "    print(tree, len(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 1, 1, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0], 0.125)\n",
      "([0, 0, 0, 0, 1, 0, 1, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 0, 0, 1, 1, 0, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0], 0.03125)\n",
      "([0, 0, 0, 0, 1, 1, 1, 0, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0], 0.03125)\n",
      "([0, 0, 0, 1, 0, 0, 1, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 0, 1, 0, 1, 0, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0], 0.03125)\n",
      "([0, 0, 0, 1, 0, 1, 1, 0, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0], 0.03125)\n",
      "([0, 0, 0, 1, 1, 0, 0, 1, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 0, 1, 1, 0, 1, 0, 1], [1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 1, 0, 0, 0, 1, 1, 1], [1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0], 0.125)\n",
      "([0, 0, 1, 0, 0, 1, 0, 1, 1], [1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 1, 0, 0, 1, 1, 0, 1], [1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], 0.0625)\n",
      "([0, 0, 1, 0, 1, 0, 0, 1, 1], [1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0], 0.125)\n",
      "([0, 0, 1, 0, 1, 0, 1, 0, 1], [1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0], 0.125)\n",
      "14\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Demo: All possible sequences of specified length.\n",
    "\n",
    "N = 5\n",
    "\n",
    "def product(p):\n",
    "    return reduce(lambda x, y: x*y, p, 1.0)\n",
    "\n",
    "sequences, probabilities = brute_force_transitions(N)\n",
    "for s, p in zip(sequences, probabilities):\n",
    "    print(s, p, product(p))\n",
    "    \n",
    "print(len(sequences))\n",
    "    \n",
    "print(sum(map(lambda x: product(x), probabilities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 1, 1, 1, 1], [1.0, 1.0, 0.643, 0.444, 0.25, 1.0, 1.0, 1.0, 1.0], 0.07142857142857142)\n",
      "([0, 0, 0, 0, 1, 0, 1, 1, 1], [1.0, 1.0, 0.643, 0.444, 0.75, 0.333, 1.0, 1.0, 1.0], 0.07142857142857142)\n",
      "([0, 0, 0, 0, 1, 1, 0, 1, 1], [1.0, 1.0, 0.643, 0.444, 0.75, 0.667, 0.5, 1.0, 1.0], 0.07142857142857144)\n",
      "([0, 0, 0, 0, 1, 1, 1, 0, 1], [1.0, 1.0, 0.643, 0.444, 0.75, 0.667, 0.5, 1.0, 1.0], 0.07142857142857144)\n",
      "([0, 0, 0, 1, 0, 0, 1, 1, 1], [1.0, 1.0, 0.643, 0.556, 0.6, 0.333, 1.0, 1.0, 1.0], 0.07142857142857144)\n",
      "([0, 0, 0, 1, 0, 1, 0, 1, 1], [1.0, 1.0, 0.643, 0.556, 0.6, 0.667, 0.5, 1.0, 1.0], 0.07142857142857145)\n",
      "([0, 0, 0, 1, 0, 1, 1, 0, 1], [1.0, 1.0, 0.643, 0.556, 0.6, 0.667, 0.5, 1.0, 1.0], 0.07142857142857145)\n",
      "([0, 0, 0, 1, 1, 0, 0, 1, 1], [1.0, 1.0, 0.643, 0.556, 0.4, 1.0, 0.5, 1.0, 1.0], 0.07142857142857144)\n",
      "([0, 0, 0, 1, 1, 0, 1, 0, 1], [1.0, 1.0, 0.643, 0.556, 0.4, 1.0, 0.5, 1.0, 1.0], 0.07142857142857144)\n",
      "([0, 0, 1, 0, 0, 0, 1, 1, 1], [1.0, 1.0, 0.357, 1.0, 0.6, 0.333, 1.0, 1.0, 1.0], 0.07142857142857141)\n",
      "([0, 0, 1, 0, 0, 1, 0, 1, 1], [1.0, 1.0, 0.357, 1.0, 0.6, 0.667, 0.5, 1.0, 1.0], 0.07142857142857142)\n",
      "([0, 0, 1, 0, 0, 1, 1, 0, 1], [1.0, 1.0, 0.357, 1.0, 0.6, 0.667, 0.5, 1.0, 1.0], 0.07142857142857142)\n",
      "([0, 0, 1, 0, 1, 0, 0, 1, 1], [1.0, 1.0, 0.357, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0], 0.07142857142857142)\n",
      "([0, 0, 1, 0, 1, 0, 1, 0, 1], [1.0, 1.0, 0.357, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0], 0.07142857142857142)\n",
      "14\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Demo: All possible sequences of specified length.\n",
    "\n",
    "N = 5\n",
    "\n",
    "sequences, probabilities = catalan_transitions(N)\n",
    "for s, p in zip(sequences, probabilities):\n",
    "    print(s, list(map(lambda x: round(x, 3), p)), product(p))\n",
    "    \n",
    "print(len(sequences))\n",
    "    \n",
    "print(sum(map(lambda x: product(x), probabilities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1], 19)\n",
      "([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1], 19)\n",
      "([0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1], 19)\n",
      "([0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], 19)\n",
      "([0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1], 19)\n",
      "([0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1], 19)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Generate a handful of random trees for a fixed length\n",
    "# using the catalan pyramid distribution.\n",
    "\n",
    "rounds = 10\n",
    "N = 10 # sentence length\n",
    "\n",
    "for _ in range(rounds):\n",
    "    tree = uniform_random_trees(N)\n",
    "    print(tree, len(tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source Data\n",
    "\n",
    "data = [\n",
    "    dict(source = '~/data/multinli_1.0/multinli_1.0_dev_mismatched.jsonl',\n",
    "    target_uniform_transitions = '~/data/multinli_1.0/multinli_1.0_dev_mismatched-random_transitions.jsonl',\n",
    "    target_uniform_trees = '~/data/multinli_1.0/multinli_1.0_dev_mismatched-random_trees.jsonl',\n",
    "    ),\n",
    "    dict(source = '~/data/multinli_1.0/multinli_1.0_dev_matched.jsonl',\n",
    "    target_uniform_transitions = '~/data/multinli_1.0/multinli_1.0_dev_matched-random_transitions.jsonl',\n",
    "    target_uniform_trees = '~/data/multinli_1.0/multinli_1.0_dev_matched-random_trees.jsonl',\n",
    "    ),\n",
    "    dict(source = '~/data/multinli_1.0/multinli_1.0_train.jsonl',\n",
    "    target_uniform_transitions = '~/data/multinli_1.0/multinli_1.0_train-random_transitions.jsonl',\n",
    "    target_uniform_trees = '~/data/multinli_1.0/multinli_1.0_train-random_trees.jsonl',\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Methods\n",
    "\n",
    "def write_dataset(dataset, target):\n",
    "    with open(target, 'w') as f:\n",
    "        for example in dataset:\n",
    "            f.write(json.dumps(example) + '\\n')\n",
    "\n",
    "def read_and_seperate_parses(source):\n",
    "    sentence1_tokens = []\n",
    "    sentence2_tokens = []\n",
    "    dataset = []\n",
    "    with open(source) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                line = line.encode('UTF-8')\n",
    "            except UnicodeError as e:\n",
    "                print \"ENCODING ERROR:\", line, e\n",
    "                line = \"{}\"\n",
    "\n",
    "            loaded_example = json.loads(line)\n",
    "\n",
    "            tokens1, _ = convert_binary_bracketing(loaded_example[\"sentence1_binary_parse\"])\n",
    "            sentence1_tokens.append(tokens1)\n",
    "            del loaded_example[\"sentence1_binary_parse\"]\n",
    "\n",
    "            tokens2, _ = convert_binary_bracketing(loaded_example[\"sentence2_binary_parse\"])\n",
    "            sentence2_tokens.append(tokens2)\n",
    "            del loaded_example[\"sentence2_binary_parse\"]\n",
    "            \n",
    "            dataset.append(loaded_example)\n",
    "    return dataset, sentence1_tokens, sentence2_tokens\n",
    "\n",
    "def generate_random_transitions(dataset, sentence1_tokens, sentence2_tokens):\n",
    "    for example, s1, s2 in zip(dataset, sentence1_tokens, sentence2_tokens):\n",
    "        s1_transitions = uniform_random_transitions(len(s1))\n",
    "        s1_binary_parse = binary_parse(s1, s1_transitions)\n",
    "        example['sentence1_binary_parse'] = s1_binary_parse\n",
    "        \n",
    "        s2_transitions = uniform_random_transitions(len(s2))\n",
    "        s2_binary_parse = binary_parse(s2, s2_transitions)\n",
    "        example['sentence2_binary_parse'] = s2_binary_parse\n",
    "    return dataset\n",
    "\n",
    "def generate_random_trees(dataset, sentence1_tokens, sentence2_tokens):\n",
    "    for example, s1, s2 in zip(dataset, sentence1_tokens, sentence2_tokens):\n",
    "        s1_transitions = uniform_random_trees(len(s1))\n",
    "        s1_binary_parse = binary_parse(s1, s1_transitions)\n",
    "        example['sentence1_binary_parse'] = s1_binary_parse\n",
    "        \n",
    "        s2_transitions = uniform_random_trees(len(s2))\n",
    "        s2_binary_parse = binary_parse(s2, s2_transitions)\n",
    "        example['sentence2_binary_parse'] = s2_binary_parse\n",
    "    return dataset\n",
    "\n",
    "def generate(source, target_uniform_transitions, target_uniform_trees):\n",
    "    \"\"\"\n",
    "    1. Read dataset into memory.\n",
    "    2. Create copy using uniform transitions.\n",
    "    3. Create copy using uniform trees.\n",
    "    \"\"\"\n",
    "    print(\"reading: {}\".format(source))\n",
    "    dataset, sentence1_tokens, sentence2_tokens = read_and_seperate_parses(source)\n",
    "    \n",
    "    assert len(sentence1_tokens) == len(sentence2_tokens)\n",
    "    assert len(sentence1_tokens) == len(dataset)\n",
    "    \n",
    "    # Random Transitions\n",
    "    print(\"building: {}\".format(target_uniform_transitions))\n",
    "    dataset_random_transitions = generate_random_transitions(dataset, sentence1_tokens, sentence2_tokens)\n",
    "    print(\"writing: {}\".format(target_uniform_transitions))\n",
    "    write_dataset(dataset_random_transitions, target_uniform_transitions)\n",
    "    \n",
    "    # Random Trees\n",
    "    print(\"building: {}\".format(target_uniform_trees))\n",
    "    dataset_random_trees = generate_random_trees(dataset, sentence1_tokens, sentence2_tokens)\n",
    "    print(\"writing: {}\".format(target_uniform_trees))\n",
    "    write_dataset(dataset_random_trees, target_uniform_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading: /home/dexter/data/multinli_1.0/multinli_1.0_dev_mismatched.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_dev_mismatched-random_transitions.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_dev_mismatched-random_transitions.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_dev_mismatched-random_trees.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_dev_mismatched-random_trees.jsonl\n",
      "reading: /home/dexter/data/multinli_1.0/multinli_1.0_dev_matched.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_dev_matched-random_transitions.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_dev_matched-random_transitions.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_dev_matched-random_trees.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_dev_matched-random_trees.jsonl\n",
      "reading: /home/dexter/data/multinli_1.0/multinli_1.0_train.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_train-random_transitions.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_train-random_transitions.jsonl\n",
      "building: /home/dexter/data/multinli_1.0/multinli_1.0_train-random_trees.jsonl\n",
      "writing: /home/dexter/data/multinli_1.0/multinli_1.0_train-random_trees.jsonl\n"
     ]
    }
   ],
   "source": [
    "def run(data_dicts, rng_seed=11):\n",
    "    np.random.seed(rng_seed)\n",
    "    for dd in data_dicts:\n",
    "        generate(\n",
    "            os.path.expanduser(dd['source']), \n",
    "            os.path.expanduser(dd['target_uniform_transitions']),\n",
    "            os.path.expanduser(dd['target_uniform_trees'])\n",
    "        )\n",
    "    \n",
    "run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
